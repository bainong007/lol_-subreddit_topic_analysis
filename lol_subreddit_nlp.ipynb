{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T15:19:54.940983Z",
     "start_time": "2019-08-22T15:19:52.502481Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas_profiling\n",
    "import spacy\n",
    "from html import unescape\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD, PCA, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T14:09:28.788739Z",
     "start_time": "2019-08-14T14:09:28.784628Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Collection DATA with Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:43:47.260868Z",
     "start_time": "2019-08-19T14:43:46.428654Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T22:19:16.024945Z",
     "start_time": "2019-08-14T22:19:15.270888Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #run a sample\n",
    "# with urllib.request.urlopen(\"https://api.pushshift.io/reddit/comment/search/?subreddit=leagueoflegends&after=1546318800&before=1564631940&sort_type=score&sort=desc&size=1000&score>500&score<800\") as url:\n",
    "#     sample = pd.DataFrame(data = json.loads(url.read().decode())['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:49:38.356575Z",
     "start_time": "2019-08-19T14:49:38.351045Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data(after, before):\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search/?size=1000&after='+str(after)+'&before='+str(before)+'&subreddit=leagueoflegends'\n",
    "    with urllib.request.urlopen(url) as url:\n",
    "        df = pd.DataFrame(data = json.loads(url.read().decode())['data'])[['created_utc','author','score','body','subreddit']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T21:58:38.995981Z",
     "start_time": "2019-08-13T21:58:38.990176Z"
    },
    "hidden": true
   },
   "source": [
    "Note:\n",
    "Use to convert time: https://www.unixtimestamp.com/index.php\n",
    "\n",
    "Jul\n",
    "- After(7/1/2018) 1530403200\n",
    "- Before(7/31/2018) 1533081599\n",
    "\n",
    "Aug\n",
    "- After(8/1/2018) 1533081600\n",
    "- Before(8/31/2018) 1535759999\n",
    "\n",
    "Sep\n",
    "- After(9/1/2018) 1535760000\n",
    "- Before(9/30/2018) 1538308799\n",
    "\n",
    "Oct\n",
    "- After(10/1/2018) 1538352000\n",
    "- Before(10/31/2018) 1541030399\n",
    "\n",
    "Nov\n",
    "- After(11/1/2018) 1541030400\n",
    "- Before(11/30/2018) 1543622399\n",
    "\n",
    "Dec\n",
    "- After(12/1/2018) 1543622400\n",
    "- Before(12/31/2018) 1546300799\n",
    "\n",
    "Jan\n",
    "- After(1/1/2019) 1546300800\n",
    "- Before(1/31/2019) 1548935999\n",
    "\n",
    "Feb\n",
    "- After(2/1/2019) 1548979200\n",
    "- Before(2/28/2019) 1551398399\n",
    "\n",
    "Mar\n",
    "- After(3/1/2019) 1551398400\n",
    "- Before(3/31/2019) 1554076799\n",
    "\n",
    "Apr\n",
    "- After(4/1/2019) 1554076800\n",
    "- Before(4/30/2019) 1556668799\n",
    "\n",
    "May\n",
    "- After(5/1/2019) 1556668800\n",
    "- Before(5/31/2019) 1559347199\n",
    "\n",
    "June\n",
    "- After(6/1/2019) 1559347200\n",
    "- Before(6/31/2019) 1561939199\n",
    "\n",
    "\n",
    "6/12/19 1560297600\n",
    "6/18/19 1560902399\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T17:27:28.287845Z",
     "start_time": "2019-08-19T17:17:26.489427Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "431783\n"
     ]
    }
   ],
   "source": [
    "df = get_data(1543622400, 1546300799)\n",
    "# Will run until all posts have been gathered \n",
    "# from the 'after' date up until before date\n",
    "error502 = 0\n",
    "while len(df) > 0:\n",
    "    # Calls get_data() with the created date of the last submission\n",
    "    try:\n",
    "        after = df['created_utc'].tail(1).item()\n",
    "        df = df.append(get_data(after, 1546300799), ignore_index=True)\n",
    "    except requests.exceptions.HTTPError:\n",
    "        error502 += 1\n",
    "        print(error502)\n",
    "        after = df['created_utc'].tail(1).item()\n",
    "        df = df.append(get_data(after, 1546300799), ignore_index=True)\n",
    "    except KeyError:\n",
    "        print(error502)\n",
    "        break\n",
    "    if error502 > 30:\n",
    "        print(error502 + ' too many try')\n",
    "        break\n",
    "        \n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T17:30:04.531791Z",
     "start_time": "2019-08-19T17:30:04.526497Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431783, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T17:30:16.734119Z",
     "start_time": "2019-08-19T17:30:15.988720Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.to_pickle('cm_18_12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:46:12.909732Z",
     "start_time": "2019-08-22T01:46:12.442421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('cm_19_06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T15:19:11.872107Z",
     "start_time": "2019-08-20T15:19:11.869124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pf = pandas_profiling.ProfileReport(df=df)\n",
    "#pf.to_file(outputfile=\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T15:19:12.255494Z",
     "start_time": "2019-08-20T15:19:12.227474Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1560297603</td>\n",
       "      <td>Maikiol</td>\n",
       "      <td>1</td>\n",
       "      <td>This happened so often in LAS, but in comparis...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560297606</td>\n",
       "      <td>supertbagman</td>\n",
       "      <td>1</td>\n",
       "      <td>o7</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560297609</td>\n",
       "      <td>GalaxyVox</td>\n",
       "      <td>59</td>\n",
       "      <td>That Alistar... Itâ€™s just too good</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1560297610</td>\n",
       "      <td>tim466</td>\n",
       "      <td>5</td>\n",
       "      <td>Riot is something called a \"company\". This has...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1560297613</td>\n",
       "      <td>narfidy</td>\n",
       "      <td>1</td>\n",
       "      <td>Caitlyn gets 2 AD while enchanters are on the ...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc        author  score  \\\n",
       "0   1560297603       Maikiol      1   \n",
       "1   1560297606  supertbagman      1   \n",
       "2   1560297609     GalaxyVox     59   \n",
       "3   1560297610        tim466      5   \n",
       "4   1560297613       narfidy      1   \n",
       "\n",
       "                                                body        subreddit  \n",
       "0  This happened so often in LAS, but in comparis...  leagueoflegends  \n",
       "1                                                 o7  leagueoflegends  \n",
       "2                 That Alistar... Itâ€™s just too good  leagueoflegends  \n",
       "3  Riot is something called a \"company\". This has...  leagueoflegends  \n",
       "4  Caitlyn gets 2 AD while enchanters are on the ...  leagueoflegends  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:46:17.720717Z",
     "start_time": "2019-08-22T01:46:16.866599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='body', keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:46:17.975072Z",
     "start_time": "2019-08-22T01:46:17.723902Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[df['author']!='Ilackfocus']\n",
    "df = df[df['author']!='[deleted]']\n",
    "df = df[df['author']!='AutoModerator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T02:41:40.179318Z",
     "start_time": "2019-08-16T02:41:40.172673Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Too Slow. Don't use.\n",
    "\n",
    "# class CustomVectorizer(CountVectorizer): \n",
    "    \n",
    "#     # overwrite the build_analyzer method, allowing one to\n",
    "#     # create a custom analyzer for the vectorizer\n",
    "#     def build_analyzer(self):\n",
    "        \n",
    "#         # load stop words using CountVectorizer's built in method\n",
    "#         stop_words = self.get_stop_words()\n",
    "        \n",
    "#         # create the analyzer that will be returned by this method\n",
    "#         def analyser(doc):\n",
    "            \n",
    "#             # load spaCy's model for english language\n",
    "#             spacy.load('en')\n",
    "            \n",
    "#             # instantiate a spaCy tokenizer\n",
    "#             lemmatizer = spacy.lang.en.English()\n",
    "            \n",
    "#             # apply the preprocessing and tokenzation steps\n",
    "#             doc_clean = unescape(doc).lower()\n",
    "#             tokens = lemmatizer(doc_clean)\n",
    "#             lemmatized_tokens = [token.lemma_ for token in tokens]\n",
    "            \n",
    "#             # use CountVectorizer's _word_ngrams built in method\n",
    "#             # to remove stop words and extract n-grams\n",
    "#             return(self._word_ngrams(lemmatized_tokens, stop_words))\n",
    "#         return(analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T03:34:34.365047Z",
     "start_time": "2019-08-16T03:34:34.043790Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create a spaCy tokenizer\n",
    "spacy.load('en')\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# remove html entities from docs and\n",
    "# set everything to lowercase\n",
    "def my_preprocessor(doc):\n",
    "    return(unescape(doc).lower())\n",
    "\n",
    "# tokenize the doc and lemmatize its tokens\n",
    "def my_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T03:51:39.828100Z",
     "start_time": "2019-08-16T03:48:00.011700Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['3', 'far', 'good', 'little', 'make', '\\ufeff1'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# This did not give me a good topic modeling result\n",
    "# custom_vec = CountVectorizer(tokenizer=my_tokenizer,\n",
    "#                              stop_words='english')\n",
    "# cwm = custom_vec.fit_transform(df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T17:55:40.669331Z",
     "start_time": "2019-08-17T17:55:21.436362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "token_pattern_no_number=u'(?ui)\\\\b\\\\w*[a-zA-Z]+\\\\w*\\\\b'\n",
    "vectorizer = CountVectorizer(stop_words = 'english', \n",
    "                             token_pattern=token_pattern_no_number, \n",
    "                             max_df=0.5,\n",
    "                             min_df=2)\n",
    "v_model = vectorizer.fit_transform(df['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T17:41:10.114431Z",
     "start_time": "2019-08-19T17:41:10.108262Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T02:20:47.200975Z",
     "start_time": "2019-08-18T02:20:44.963539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nmf_model = NMF(5)\n",
    "topic_nmf = nmf_model.fit_transform(c_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T02:20:47.229178Z",
     "start_time": "2019-08-18T02:20:47.203599Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.54834\n",
       "1    0.20266\n",
       "2    0.08459\n",
       "3    0.08227\n",
       "4    0.08214\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(topic_nmf.argmax(axis=1)).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T02:46:24.635390Z",
     "start_time": "2019-08-18T02:46:24.603140Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "play, even, one, people, think, good, would, really, also, time, much, still, make, know, well, way, players, lot, see, games, better, lane, actually, playing, could, top, pretty, say, want, since\n",
      "\n",
      "Topic  1\n",
      "g2, tl, team, ig, skt, na, best, better, teams, win, vs, msi, eu, worlds, think, would, finals, beat, world, even, tournament, last, got, pvb, well, top, lost, year, still, games\n",
      "\n",
      "Topic  2\n",
      "like, feel, something, looks, seems, shit, people, look, really, feels, sounds, yeah, would, playing, things, see, said, stuff, lol, know, maybe, someone, mean, felt, always, make, champs, league, saying, etc\n",
      "\n",
      "Topic  3\n",
      "game, every, early, play, games, playing, win, late, played, lane, mid, lose, minutes, got, first, single, one, lost, bad, fun, league, hard, team, gold, shit, vs, bot, back, losing, winning\n",
      "\n",
      "Topic  4\n",
      "get, team, back, go, games, need, win, enemy, getting, want, enough, hard, kill, shit, try, time, lose, dont, gold, lane, away, help, take, banned, going, someone, way, gets, skin, free\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_model, vectorizer_corex.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:22:13.039183Z",
     "start_time": "2019-08-15T14:22:12.973415Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['topic'] = topic_nmf.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:41:19.050280Z",
     "start_time": "2019-08-15T14:41:19.014449Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.755664\n",
       "4    0.161139\n",
       "3    0.048293\n",
       "1    0.029253\n",
       "2    0.005651\n",
       "Name: topic, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T20:30:47.183696Z",
     "start_time": "2019-08-14T20:30:47.134081Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        topic  \\\n",
      "186850      0   \n",
      "\n",
      "                                                                                                                      body  \n",
      "186850  That might be it: I donâ€™t bother with ranked, as if find everyone salty enough without fake gamepoint at stake lol  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', 500):\n",
    "    print (df[['topic', 'body']].sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:23:07.374921Z",
     "start_time": "2019-08-15T14:23:06.012566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle('cm_19_02')\n",
    "df2.drop_duplicates(subset='body', keep=False, inplace=True)\n",
    "df2 = df2[df2['author']!='Ilackfocus']\n",
    "df2 = df2[df2['author']!='[deleted]']\n",
    "df2 = df2[df2['author']!='AutoModerator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:57:18.139160Z",
     "start_time": "2019-08-15T14:57:05.211798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_model2 = vectorizer.transform(df2['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:57:18.725601Z",
     "start_time": "2019-08-15T14:57:18.141468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "topic2_nmf = nmf_model.transform(v_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T14:58:52.858032Z",
     "start_time": "2019-08-15T14:58:52.837369Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.738020\n",
       "4    0.172445\n",
       "3    0.048796\n",
       "1    0.028051\n",
       "2    0.012688\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(topic2_nmf.argmax(axis=1)).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T17:21:36.916302Z",
     "start_time": "2019-08-16T17:21:33.549812Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(4)\n",
    "topic_lsa = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T17:21:36.939395Z",
     "start_time": "2019-08-16T17:21:36.918738Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.879674\n",
       "1    0.049115\n",
       "3    0.040619\n",
       "2    0.030592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(topic_lsa.argmax(axis=1)).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T17:21:37.152145Z",
     "start_time": "2019-08-16T17:21:36.942926Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "game, just, like, g2, tl, play, team, ig, don, good, think, skt, people, really, better, na, games, win, best, time, know, playing, lol, did, bad, vs, players, gt, got, lane\n",
      "\n",
      "Topic  1\n",
      "g2, tl, ig, skt, vs, pvb, beat, win, na, finals, eu, team, fw, msi, bo5, teams, better, worlds, series, groups, best, fans, lost, won, tournament, tsm, wins, final, fan, fnc\n",
      "\n",
      "Topic  2\n",
      "game, skt, g2, ig, play, early, late, games, lane, playing, fun, played, pvb, lost, minutes, win, draft, lose, mid, bot, gold, pick, champ, fw, ranked, baron, kills, single, lead, mode\n",
      "\n",
      "Topic  3\n",
      "game, na, eu, best, team, lol, tl, fans, region, https, early, teams, worlds, com, world, players, msi, late, player, c9, international, vs, win, tsm, finals, fan, won, xmithie, watch, good\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa, tfidf.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CorEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Anchor Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:04.443235Z",
     "start_time": "2019-08-20T18:30:04.438580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "league = ['LCS', 'LEC', 'LCK', 'LPL', 'LMS','VCS', \n",
    "          'LCL', 'TCL', 'CBLOL', 'LLA', 'LJL','OPL', 'LST']\n",
    "league = [item.lower() for item in league]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:05.369442Z",
     "start_time": "2019-08-20T18:30:05.365327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tournament = ['msi', 'world','tournament', 'region', 'na','eu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:06.292488Z",
     "start_time": "2019-08-20T18:30:06.277661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hero = pd.read_csv('hero_list')\n",
    "hero = hero['Hero'].values.tolist()\n",
    "hero = [item.lower() for item in hero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:10.649125Z",
     "start_time": "2019-08-20T18:30:10.645271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position = ['top', 'jungle','mid','adc', 'support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:11.594310Z",
     "start_time": "2019-08-20T18:30:11.589920Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "team = ['ig','skt','tl','c9','tsm','fnc','faker','jensen','uzi','bjergsen','doublelift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:12.584966Z",
     "start_time": "2019-08-20T18:30:12.581050Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rank = ['ranked','rank','elo','bronze','silver','gold','master','challenger','diamond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:13.656244Z",
     "start_time": "2019-08-20T18:30:13.652602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "skin = ['buy','skin','skins','money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T18:30:16.977629Z",
     "start_time": "2019-08-20T18:30:16.973884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anchors = [league+tournament+team, position, rank, skin, hero]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T19:02:20.407237Z",
     "start_time": "2019-08-17T19:02:20.403660Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### CorEx Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:46:26.565023Z",
     "start_time": "2019-08-22T01:46:26.561404Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:46:28.765506Z",
     "start_time": "2019-08-22T01:46:28.759544Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:49:46.868012Z",
     "start_time": "2019-08-22T01:49:46.863632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "infile = open('stopword_400_list','rb')\n",
    "stop400 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:50:25.836655Z",
     "start_time": "2019-08-22T01:50:25.833322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stopwords= stopwords + stop400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:51:39.133149Z",
     "start_time": "2019-08-22T01:51:02.058069Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_pattern_no_number=u'(?ui)\\\\b\\\\w*[a-zA-Z]+\\\\w*\\\\b'\n",
    "vectorizer_corex = CountVectorizer(stop_words = stopwords, \n",
    "                             binary=True,\n",
    "                             token_pattern=token_pattern_no_number,\n",
    "                             ngram_range=(1, 2),\n",
    "                             max_df=0.5,\n",
    "                             min_df=2,\n",
    "                             max_features=40000)\n",
    "c_word = vectorizer_corex.fit_transform(df['body'])\n",
    "vocab = vectorizer_corex.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:57:55.213212Z",
     "start_time": "2019-08-22T01:57:55.208054Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476544, 40000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T15:35:49.086889Z",
     "start_time": "2019-08-20T15:35:49.082667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "morde = [['mordekaiser','damage'], ['morde','damage'], ['mordekaiser','ult'],['morde','ult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T03:37:06.856031Z",
     "start_time": "2019-08-22T03:33:37.323538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seed#42 is a good one.\n",
    "ct_model = ct.Corex(n_hidden=6, seed=40)\n",
    "c_model_fitted = ct_model.fit(c_word, words=vocab) #, anchors=anchors, anchor_strength=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T03:37:10.463847Z",
     "start_time": "2019-08-22T03:37:06.858476Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:  0.11510164853612678\n",
      "Topic #2:  0.16427863953800698\n",
      "Topic #3:  0.11384258326618318\n",
      "Topic #4:  0.1462823999462799\n",
      "Topic #5:  0.12085137993553585\n",
      "Topic #6:  0.059568476363148\n",
      "No Topic : 0.533228830915928\n"
     ]
    }
   ],
   "source": [
    "def topic_dist(fitted_model):\n",
    "    topic_count = np.asarray(fitted_model.labels).sum(axis=0)\n",
    "    no_topic_count = 0\n",
    "    for i, topic_ngrams in enumerate(topic_count):\n",
    "        print(\"Topic #{}: \".format(i+1), topic_count[i]/len(fitted_model.labels))\n",
    "    for doc in fitted_model.labels:\n",
    "        if doc.sum() == 0:\n",
    "            no_topic_count += 1\n",
    "    print('No Topic :', no_topic_count/len(fitted_model.labels))\n",
    "topic_dist(c_model_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T03:37:11.081137Z",
     "start_time": "2019-08-22T03:37:10.467321Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #1: damage, q, e, w, items, item, ap, passive, build, shield, cc, mana, kit, tank, ad, hp, kill, healing, dmg, sa, ability, kai sa, kai, health, speed, abilities, cd, heal, nerf, tanks, assassin, poke, buff, burst, mage, sustain, attack, phase, laning, wave, mages, melee, laning phase, ranged, cdr, auto, lux, mobility, aoe, target, irelia, max, bruiser, minions, scaling, cooldown, armor, akali, base, darius\n",
      "\n",
      "Topic #2: different, elo, skill, gold, ranked, skins, lower, balance, change, fun, plat, diamond, silver, changes, agree, rank, pro, buy, single, experience, map, simply, season, climb, design, mmr, certain, comes, current, free, others, important, mechanics, skin, similar, small, overall, easier, possible, compared, mostly, general, control, obviously, argument, lp, average, whatever, potential, opinion, whether, given, ones, focus, extremely, personally, normal, lack, situation, mind\n",
      "\n",
      "Topic #3: na, g2, eu, tl, worlds, tsm, msi, split, c9, fnc, skt, ig, region, fans, tournament, lcs, spring, world, lec, fnatic, international, rift rivals, rivals, og, vs, lck, summer, fan, rr, message compose, lpl, compose, playoffs, rift, talent, perkz, bo5, regions, lost, na eu, eu na, roster, stage, korea, fox, academy, rookie, dl, jensen, groups, looked, clg, 100t, broxah, import, spring split, imports, message, kr, zven\n",
      "\n",
      "Topic #4: riot, money, server, system, banned, client, servers, rules, company, tft, live, account, streamers, stream, community, nb3, content, hours, wrong, issues, country, question, pay, report, attention, en, esports, twitch, youtube, subreddit, streamer, pbe, posts, information, allowed, type, sports, countries, videos, mods, discuss, english, euw, working, american, page, legends, fix, spend, screen, break, dota, wants, scene, clearly, ticket, life, monte, days, friends\n",
      "\n",
      "Topic #5: mid, top, adc, support, pick, solo, jungle, bot, jungler, role, lanes, strong, tahm, laners, carry, pyke, tower, gank, farm, cs, winrate, picks, solo queue, kench, kills, tahm kench, counter, supports, push, lee sin, teemo, sin, lee, pressure, turret, picked, lead, roam, jg, vision, ahead, ban, ganks, fed, botlane, zed, matchup, junglers, matchups, riven, top mid, adcs, roaming, queue, roles, weak, safe, baron, yi, yasuo\n",
      "\n",
      "Topic #6: ult, taric, sona, sona taric, r, realm, flash, sylas, morde, stun, death, wall, dash, ults, death realm, seconds, cast, qss, splash, combo, body, wiki, engage, yuumi, rakan, art, splash art, github, uma jan, uma, xayah, jan, http, lore, animation, morde ult, jpg, status, land, np message, mordekaiser, images, twitter, press, g, neeko, type bug, xayah rakan, hook, np, qiyana, shadow, creator, source, subject, escape, steps reproduce, reproduction, short, observed result\n"
     ]
    }
   ],
   "source": [
    "for i, topic_ngrams in enumerate(c_model_fitted.get_topics(n_words=60)):\n",
    "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
    "    print(\"\\nTopic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
